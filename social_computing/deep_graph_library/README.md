# Questions

### Q1. Consider the graphs below. Which one of the four graphs is most likely to have been generated by a random graph model Gn,p with n = 5 and p = 0.8? Explain clearly.
![Alt text](./graphs.jpg?raw=true "graphs")

### Q2. Deep Graph Library (DGL)
In this question, you are required to use DGL to build a graph neural network for node classification. The
dataset hw dataset.pkl can be downloaded from 

https://drive.google.com/file/d/1QA4HEsAKtyg9tGrOvIDWltu9lx6t_T2v/view?usp=sharing

1. Load the dataset with the following command:

```python
dataset = pkl.load(open("hw_dataset.pkl", "rb"))
```

This file contains a dictionary object with the following information of a directed graph:
- nodes: a list containing the id’s of all the nodes in the graph;
- labels: a list containing the label of each node;
- num classes: the total number of node labels;
- features: a matrix of size: number-of-nodes × feature-dimensionality;
- source nodes: a list containing the source node-id of each (directed) edge;
- target nodes: a list containing the target node-id of each (directed) edge;
- train mask: a list (of values “True” or “False”) indicating whether each node is used in the training set or not;
- val mask: This has the same format as train mask, and shows whether each node is used in the validation set or not.

2. You have to use the graph neural network model dgl.nn.pytorch.conv.GINConv in DGL. It implements the following neighborhood aggregation:
![Alt text](./formula.jpg?raw=true "formula")

This model includes the graph neural network model discussed in class, but is more general. For details,
read https://docs.dgl.ai/api/python/nn.pytorch.html#dgl.nn.pytorch.conv.GINConv.

3. Your tasks are as follows:
(a) By varying the number of GINConv layers, dimension of hidden features, activation function and aggregation type (sum, max or mean), find a model (“best model.pth”) with high node classification accuracy.
Show how you obtain the best model. Specifically, you need to provide all models you tried. Then, report
your best model in terms of node classification accuracy on the validation set.

- Your grade will be partly based on your model’s node classification accuracy on a test set (which is
hidden from you).
- We will use the following code to test your model.
- Your code should include a test function (with your model and a mask as inputs) so that we do not need to retrain your model.
```python
load_checkpoint("best_model.pth", model)
# the test_mask here is hidden for you. you can replace the test_mask with the val_mask.
accuracy = test(model, test_mask)
print("Testing Acc {:.4}".format(accuracy))
```

Please also use the following functions
- to save your final model:
```python
def save_checkpoint(checkpoint_path, model):
  # state_dict: a Python dictionary object that:
  # - for a model, maps each layer to its parameter tensor;
  state = {’state_dict’: model.state_dict()}
  torch.save(state, checkpoint_path)
  print(’model saved to %s’ % checkpoint_path)
  
save_checkpoint("best_model.pth", model)
```
- to reload your model for evaluation:
```python
def load_checkpoint(checkpoint_path, model):
  state = torch.load(checkpoint_path)
  model.load_state_dict(state[’state_dict’])
  print(’model loaded from %s’ % checkpoint_path)

load_checkpoint("best_model.pth", model)
```

(b) Generate a random feature matrix with the same shape (number-of-nodes × feature-dimensionality)
as the original feature matrix. Each element in the random feature matrix is randomly sampled from the
uniform distribution between [0, 1) (use np.random.rand() to generate the random feature matrix and please
set your random seed to be 5008).
(c) Using the same model you have in (a), re-train it with the random features you generated in (b). Name
this new model “best model random.pth”.
- Report the validation set accuracy (using val mask) obtained by the model here.
- Compare your results in (a) and comment on the results.
