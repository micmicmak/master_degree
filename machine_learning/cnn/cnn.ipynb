{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6f1b5b",
   "metadata": {},
   "source": [
    "### <font color='red'>Original</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f02cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.238\n",
      "[1,  4000] loss: 1.912\n",
      "[1,  6000] loss: 1.702\n",
      "[1,  8000] loss: 1.614\n",
      "[1, 10000] loss: 1.557\n",
      "[1, 12000] loss: 1.525\n",
      "[2,  2000] loss: 1.435\n",
      "[2,  4000] loss: 1.419\n",
      "[2,  6000] loss: 1.359\n",
      "[2,  8000] loss: 1.347\n",
      "[2, 10000] loss: 1.316\n",
      "[2, 12000] loss: 1.302\n",
      "Training time: 106.05685758590698\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "Accuracy of plane : 68 %\n",
      "Accuracy of   car : 71 %\n",
      "Accuracy of  bird : 32 %\n",
      "Accuracy of   cat : 21 %\n",
      "Accuracy of  deer : 41 %\n",
      "Accuracy of   dog : 61 %\n",
      "Accuracy of  frog : 67 %\n",
      "Accuracy of horse : 65 %\n",
      "Accuracy of  ship : 63 %\n",
      "Accuracy of truck : 68 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f333f",
   "metadata": {},
   "source": [
    "### <font color='red'>Vary the number of hidden layers </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ab2e6",
   "metadata": {},
   "source": [
    "#### Reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3824f",
   "metadata": {},
   "source": [
    "#### 1fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eee81461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.130\n",
      "[1,  4000] loss: 1.766\n",
      "[1,  6000] loss: 1.582\n",
      "[1,  8000] loss: 1.482\n",
      "[1, 10000] loss: 1.440\n",
      "[1, 12000] loss: 1.421\n",
      "[2,  2000] loss: 1.333\n",
      "[2,  4000] loss: 1.357\n",
      "[2,  6000] loss: 1.305\n",
      "[2,  8000] loss: 1.280\n",
      "[2, 10000] loss: 1.295\n",
      "[2, 12000] loss: 1.296\n",
      "Training time: 98.58192157745361\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:   deer  ship  ship plane\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "Accuracy of plane : 64 %\n",
      "Accuracy of   car : 78 %\n",
      "Accuracy of  bird : 29 %\n",
      "Accuracy of   cat : 37 %\n",
      "Accuracy of  deer : 62 %\n",
      "Accuracy of   dog : 45 %\n",
      "Accuracy of  frog : 61 %\n",
      "Accuracy of horse : 62 %\n",
      "Accuracy of  ship : 66 %\n",
      "Accuracy of truck : 55 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b385d5",
   "metadata": {},
   "source": [
    "#### 2fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef7facb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.086\n",
      "[1,  4000] loss: 1.743\n",
      "[1,  6000] loss: 1.616\n",
      "[1,  8000] loss: 1.551\n",
      "[1, 10000] loss: 1.476\n",
      "[1, 12000] loss: 1.421\n",
      "[2,  2000] loss: 1.353\n",
      "[2,  4000] loss: 1.324\n",
      "[2,  6000] loss: 1.316\n",
      "[2,  8000] loss: 1.296\n",
      "[2, 10000] loss: 1.258\n",
      "[2, 12000] loss: 1.227\n",
      "Training time: 110.281911611557\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship   car plane\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "Accuracy of plane : 53 %\n",
      "Accuracy of   car : 66 %\n",
      "Accuracy of  bird : 35 %\n",
      "Accuracy of   cat : 39 %\n",
      "Accuracy of  deer : 59 %\n",
      "Accuracy of   dog : 46 %\n",
      "Accuracy of  frog : 69 %\n",
      "Accuracy of horse : 64 %\n",
      "Accuracy of  ship : 65 %\n",
      "Accuracy of truck : 72 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f087b23",
   "metadata": {},
   "source": [
    "#### Increased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1ab4e",
   "metadata": {},
   "source": [
    "#### 4fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6d2dd93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.302\n",
      "[1,  4000] loss: 2.164\n",
      "[1,  6000] loss: 1.868\n",
      "[1,  8000] loss: 1.703\n",
      "[1, 10000] loss: 1.607\n",
      "[1, 12000] loss: 1.553\n",
      "[2,  2000] loss: 1.495\n",
      "[2,  4000] loss: 1.444\n",
      "[2,  6000] loss: 1.426\n",
      "[2,  8000] loss: 1.423\n",
      "[2, 10000] loss: 1.374\n",
      "[2, 12000] loss: 1.360\n",
      "Training time: 135.1483416557312\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship   car  ship\n",
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 80 %\n",
      "Accuracy of  bird : 29 %\n",
      "Accuracy of   cat : 19 %\n",
      "Accuracy of  deer : 46 %\n",
      "Accuracy of   dog : 49 %\n",
      "Accuracy of  frog : 67 %\n",
      "Accuracy of horse : 66 %\n",
      "Accuracy of  ship : 63 %\n",
      "Accuracy of truck : 59 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 200)\n",
    "        self.fc2 = nn.Linear(200, 120)\n",
    "        self.fc3 = nn.Linear(120, 60)\n",
    "        self.fc4 = nn.Linear(60, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443c63c",
   "metadata": {},
   "source": [
    "#### 5fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6747d567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.297\n",
      "[1,  6000] loss: 2.145\n",
      "[1,  8000] loss: 2.012\n",
      "[1, 10000] loss: 1.949\n",
      "[1, 12000] loss: 1.906\n",
      "[2,  2000] loss: 1.772\n",
      "[2,  4000] loss: 1.681\n",
      "[2,  6000] loss: 1.623\n",
      "[2,  8000] loss: 1.576\n",
      "[2, 10000] loss: 1.517\n",
      "[2, 12000] loss: 1.470\n",
      "Training time: 129.74472546577454\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:   bird  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "Accuracy of plane : 47 %\n",
      "Accuracy of   car : 73 %\n",
      "Accuracy of  bird : 15 %\n",
      "Accuracy of   cat : 19 %\n",
      "Accuracy of  deer : 55 %\n",
      "Accuracy of   dog : 34 %\n",
      "Accuracy of  frog : 66 %\n",
      "Accuracy of horse : 53 %\n",
      "Accuracy of  ship : 76 %\n",
      "Accuracy of truck : 47 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 25)\n",
    "        self.fc5 = nn.Linear(25, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3a6ad",
   "metadata": {},
   "source": [
    "### Vary the number of filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5ef60",
   "metadata": {},
   "source": [
    "#### Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50911768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.230\n",
      "[1,  4000] loss: 1.956\n",
      "[1,  6000] loss: 1.762\n",
      "[1,  8000] loss: 1.681\n",
      "[1, 10000] loss: 1.616\n",
      "[1, 12000] loss: 1.597\n",
      "[2,  2000] loss: 1.558\n",
      "[2,  4000] loss: 1.515\n",
      "[2,  6000] loss: 1.520\n",
      "[2,  8000] loss: 1.462\n",
      "[2, 10000] loss: 1.472\n",
      "[2, 12000] loss: 1.449\n",
      "Training time: 110.74969482421875\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:  truck  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 48 %\n",
      "Accuracy of plane : 42 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 23 %\n",
      "Accuracy of   cat : 46 %\n",
      "Accuracy of  deer : 39 %\n",
      "Accuracy of   dog : 20 %\n",
      "Accuracy of  frog : 57 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 69 %\n",
      "Accuracy of truck : 57 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 5, 5)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 5 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6cd6c",
   "metadata": {},
   "source": [
    "#### Increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aad26e75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.152\n",
      "[1,  4000] loss: 1.791\n",
      "[1,  6000] loss: 1.611\n",
      "[1,  8000] loss: 1.506\n",
      "[1, 10000] loss: 1.469\n",
      "[1, 12000] loss: 1.373\n",
      "[2,  2000] loss: 1.318\n",
      "[2,  4000] loss: 1.300\n",
      "[2,  6000] loss: 1.270\n",
      "[2,  8000] loss: 1.253\n",
      "[2, 10000] loss: 1.217\n",
      "[2, 12000] loss: 1.198\n",
      "Training time: 123.12398505210876\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship   car plane\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "Accuracy of plane : 68 %\n",
      "Accuracy of   car : 64 %\n",
      "Accuracy of  bird : 20 %\n",
      "Accuracy of   cat : 40 %\n",
      "Accuracy of  deer : 46 %\n",
      "Accuracy of   dog : 52 %\n",
      "Accuracy of  frog : 71 %\n",
      "Accuracy of horse : 71 %\n",
      "Accuracy of  ship : 55 %\n",
      "Accuracy of truck : 81 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 24, 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 24 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da98e2",
   "metadata": {},
   "source": [
    "### Vary the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f250ac",
   "metadata": {},
   "source": [
    "#### lr=0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7936911",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.085\n",
      "[1,  4000] loss: 1.738\n",
      "[1,  6000] loss: 1.607\n",
      "[1,  8000] loss: 1.545\n",
      "[1, 10000] loss: 1.485\n",
      "[1, 12000] loss: 1.444\n",
      "[2,  2000] loss: 1.383\n",
      "[2,  4000] loss: 1.377\n",
      "[2,  6000] loss: 1.324\n",
      "[2,  8000] loss: 1.320\n",
      "[2, 10000] loss: 1.329\n",
      "[2, 12000] loss: 1.297\n",
      "Training time: 114.19369006156921\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat truck truck  ship\n",
      "Accuracy of the network on the 10000 test images: 52 %\n",
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 58 %\n",
      "Accuracy of  bird : 57 %\n",
      "Accuracy of   cat : 24 %\n",
      "Accuracy of  deer : 23 %\n",
      "Accuracy of   dog : 20 %\n",
      "Accuracy of  frog : 71 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 70 %\n",
      "Accuracy of truck : 83 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d77639",
   "metadata": {},
   "source": [
    "#### lr=0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89a213a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.005\n",
      "[1,  4000] loss: 1.701\n",
      "[1,  6000] loss: 1.624\n",
      "[1,  8000] loss: 1.604\n",
      "[1, 10000] loss: 1.567\n",
      "[1, 12000] loss: 1.556\n",
      "[2,  2000] loss: 1.515\n",
      "[2,  4000] loss: 1.499\n",
      "[2,  6000] loss: 1.511\n",
      "[2,  8000] loss: 1.484\n",
      "[2, 10000] loss: 1.489\n",
      "[2, 12000] loss: 1.502\n",
      "Training time: 134.2061893939972\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship plane  ship\n",
      "Accuracy of the network on the 10000 test images: 49 %\n",
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 78 %\n",
      "Accuracy of  bird : 32 %\n",
      "Accuracy of   cat : 23 %\n",
      "Accuracy of  deer : 19 %\n",
      "Accuracy of   dog : 47 %\n",
      "Accuracy of  frog : 72 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 62 %\n",
      "Accuracy of truck : 40 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.004, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a6d6b",
   "metadata": {},
   "source": [
    "#### lr=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4c97d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.293\n",
      "[1,  4000] loss: 2.057\n",
      "[1,  6000] loss: 1.864\n",
      "[1,  8000] loss: 1.746\n",
      "[1, 10000] loss: 1.661\n",
      "[1, 12000] loss: 1.592\n",
      "[2,  2000] loss: 1.524\n",
      "[2,  4000] loss: 1.487\n",
      "[2,  6000] loss: 1.469\n",
      "[2,  8000] loss: 1.419\n",
      "[2, 10000] loss: 1.378\n",
      "[2, 12000] loss: 1.358\n",
      "Training time: 132.78048586845398\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "Accuracy of plane : 51 %\n",
      "Accuracy of   car : 56 %\n",
      "Accuracy of  bird : 47 %\n",
      "Accuracy of   cat : 29 %\n",
      "Accuracy of  deer : 32 %\n",
      "Accuracy of   dog : 50 %\n",
      "Accuracy of  frog : 48 %\n",
      "Accuracy of horse : 61 %\n",
      "Accuracy of  ship : 76 %\n",
      "Accuracy of truck : 61 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0628d41",
   "metadata": {},
   "source": [
    "#### lr=0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb0cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.302\n",
      "[1,  4000] loss: 2.288\n",
      "[1,  6000] loss: 2.152\n",
      "[1,  8000] loss: 1.974\n",
      "[1, 10000] loss: 1.879\n",
      "[1, 12000] loss: 1.813\n",
      "[2,  2000] loss: 1.732\n",
      "[2,  4000] loss: 1.656\n",
      "[2,  6000] loss: 1.625\n",
      "[2,  8000] loss: 1.589\n",
      "[2, 10000] loss: 1.527\n",
      "[2, 12000] loss: 1.502\n",
      "Training time: 111.08484077453613\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:   frog  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 45 %\n",
      "Accuracy of plane : 48 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat :  7 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 46 %\n",
      "Accuracy of  frog : 69 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 59 %\n",
      "Accuracy of truck : 57 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.00025, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c268422",
   "metadata": {},
   "source": [
    "### Try different optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c60540",
   "metadata": {},
   "source": [
    "#### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160945e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.118\n",
      "[1,  4000] loss: 1.960\n",
      "[1,  6000] loss: 1.902\n",
      "[1,  8000] loss: 1.883\n",
      "[1, 10000] loss: 1.867\n",
      "[1, 12000] loss: 1.838\n",
      "[2,  2000] loss: 1.817\n",
      "[2,  4000] loss: 1.795\n",
      "[2,  6000] loss: 1.798\n",
      "[2,  8000] loss: 1.769\n",
      "[2, 10000] loss: 1.762\n",
      "[2, 12000] loss: 1.760\n",
      "Training time: 115.12477779388428\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 36 %\n",
      "Accuracy of plane : 45 %\n",
      "Accuracy of   car : 43 %\n",
      "Accuracy of  bird :  9 %\n",
      "Accuracy of   cat : 10 %\n",
      "Accuracy of  deer : 26 %\n",
      "Accuracy of   dog : 43 %\n",
      "Accuracy of  frog : 60 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 35 %\n",
      "Accuracy of truck : 47 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adagrad(net.parameters(), lr=0.001)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6fd6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 1.865\n",
      "[1,  4000] loss: 1.606\n",
      "[1,  6000] loss: 1.512\n",
      "[1,  8000] loss: 1.463\n",
      "[1, 10000] loss: 1.413\n",
      "[1, 12000] loss: 1.400\n",
      "[2,  2000] loss: 1.326\n",
      "[2,  4000] loss: 1.328\n",
      "[2,  6000] loss: 1.312\n",
      "[2,  8000] loss: 1.302\n",
      "[2, 10000] loss: 1.306\n",
      "[2, 12000] loss: 1.259\n",
      "Training time: 146.7821307182312\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship  ship\n",
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "Accuracy of plane : 59 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 44 %\n",
      "Accuracy of   cat : 21 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 56 %\n",
      "Accuracy of  frog : 50 %\n",
      "Accuracy of horse : 59 %\n",
      "Accuracy of  ship : 73 %\n",
      "Accuracy of truck : 59 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee063771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 1.895\n",
      "[1,  4000] loss: 1.593\n",
      "[1,  6000] loss: 1.509\n",
      "[1,  8000] loss: 1.445\n",
      "[1, 10000] loss: 1.425\n",
      "[1, 12000] loss: 1.370\n",
      "[2,  2000] loss: 1.321\n",
      "[2,  4000] loss: 1.306\n",
      "[2,  6000] loss: 1.277\n",
      "[2,  8000] loss: 1.289\n",
      "[2, 10000] loss: 1.280\n",
      "[2, 12000] loss: 1.260\n",
      "Training time: 153.4653377532959\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:   bird  ship   car  ship\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "Accuracy of plane : 61 %\n",
      "Accuracy of   car : 71 %\n",
      "Accuracy of  bird : 39 %\n",
      "Accuracy of   cat : 20 %\n",
      "Accuracy of  deer : 44 %\n",
      "Accuracy of   dog : 54 %\n",
      "Accuracy of  frog : 74 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 73 %\n",
      "Accuracy of truck : 67 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=0.001)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc1faa",
   "metadata": {},
   "source": [
    "### Try batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed54d1",
   "metadata": {},
   "source": [
    "#### Only fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa7bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.035\n",
      "[1,  4000] loss: 1.864\n",
      "[1,  6000] loss: 1.813\n",
      "[1,  8000] loss: 1.768\n",
      "[1, 10000] loss: 1.754\n",
      "[1, 12000] loss: 1.733\n",
      "[2,  2000] loss: 1.689\n",
      "[2,  4000] loss: 1.668\n",
      "[2,  6000] loss: 1.643\n",
      "[2,  8000] loss: 1.638\n",
      "[2, 10000] loss: 1.621\n",
      "[2, 12000] loss: 1.621\n",
      "Training time: 133.3203980922699\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:   frog  ship  ship horse\n",
      "Accuracy of the network on the 10000 test images: 42 %\n",
      "Accuracy of plane : 43 %\n",
      "Accuracy of   car : 50 %\n",
      "Accuracy of  bird :  7 %\n",
      "Accuracy of   cat : 11 %\n",
      "Accuracy of  deer : 40 %\n",
      "Accuracy of   dog : 44 %\n",
      "Accuracy of  frog : 57 %\n",
      "Accuracy of horse : 47 %\n",
      "Accuracy of  ship : 61 %\n",
      "Accuracy of truck : 58 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        #self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize.\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "########################################################################\n",
    "# See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "# for more details on saving PyTorch models.\n",
    "#\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "########################################################################\n",
    "# Okay, so what next?\n",
    "#\n",
    "# How do we run these neural networks on the GPU?\n",
    "#\n",
    "# Training on GPU\n",
    "# ----------------\n",
    "# Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "# net onto the GPU.\n",
    "#\n",
    "# Let's first define our device as the first visible cuda device if we have\n",
    "# CUDA available:\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a962c",
   "metadata": {},
   "source": [
    "#### Only conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76c876e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 1.998\n",
      "[1,  4000] loss: 1.710\n",
      "[1,  6000] loss: 1.611\n",
      "[1,  8000] loss: 1.547\n",
      "[1, 10000] loss: 1.519\n",
      "[1, 12000] loss: 1.471\n",
      "[2,  2000] loss: 1.405\n",
      "[2,  4000] loss: 1.396\n",
      "[2,  6000] loss: 1.352\n",
      "[2,  8000] loss: 1.359\n",
      "[2, 10000] loss: 1.330\n",
      "[2, 12000] loss: 1.285\n",
      "Training time: 131.52286863327026\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat   car   car  bird\n",
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "Accuracy of plane : 54 %\n",
      "Accuracy of   car : 74 %\n",
      "Accuracy of  bird : 36 %\n",
      "Accuracy of   cat : 41 %\n",
      "Accuracy of  deer : 49 %\n",
      "Accuracy of   dog : 39 %\n",
      "Accuracy of  frog : 53 %\n",
      "Accuracy of horse : 61 %\n",
      "Accuracy of  ship : 52 %\n",
      "Accuracy of truck : 70 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize.\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "########################################################################\n",
    "# See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "# for more details on saving PyTorch models.\n",
    "#\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "########################################################################\n",
    "# Okay, so what next?\n",
    "#\n",
    "# How do we run these neural networks on the GPU?\n",
    "#\n",
    "# Training on GPU\n",
    "# ----------------\n",
    "# Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "# net onto the GPU.\n",
    "#\n",
    "# Let's first define our device as the first visible cuda device if we have\n",
    "# CUDA available:\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db284f5",
   "metadata": {},
   "source": [
    "#### Conv and fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daf0f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1,  2000] loss: 2.029\n",
      "[1,  4000] loss: 1.861\n",
      "[1,  6000] loss: 1.793\n",
      "[1,  8000] loss: 1.752\n",
      "[1, 10000] loss: 1.729\n",
      "[1, 12000] loss: 1.700\n",
      "[2,  2000] loss: 1.659\n",
      "[2,  4000] loss: 1.644\n",
      "[2,  6000] loss: 1.632\n",
      "[2,  8000] loss: 1.620\n",
      "[2, 10000] loss: 1.595\n",
      "[2, 12000] loss: 1.586\n",
      "Training time: 145.26568222045898\n",
      "Finished Training\n",
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    dog  ship truck  deer\n",
      "Accuracy of the network on the 10000 test images: 44 %\n",
      "Accuracy of plane : 49 %\n",
      "Accuracy of   car : 58 %\n",
      "Accuracy of  bird : 19 %\n",
      "Accuracy of   cat : 14 %\n",
      "Accuracy of  deer : 37 %\n",
      "Accuracy of   dog : 40 %\n",
      "Accuracy of  frog : 63 %\n",
      "Accuracy of horse : 55 %\n",
      "Accuracy of  ship : 56 %\n",
      "Accuracy of truck : 51 %\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# %load ./cifar10_cnn.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 2. Define a Convolutional Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Copy the neural network from the Neural Networks section before and modify it to\n",
    "# take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#net = Net()\n",
    "\n",
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "########################################################################\n",
    "# 4. Train the network\n",
    "# ^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# This is when things start to get interesting.\n",
    "# We simply have to loop over our data iterator, and feed the inputs to the\n",
    "# network and optimize.\n",
    "if __name__=='__main__':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "                'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training time:', (time.time() - start_time))\n",
    "    print('Finished Training')\n",
    "\n",
    "########################################################################\n",
    "# Let's quickly save our trained model:\n",
    "\n",
    "    PATH = './cifar_net.pth'\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "\n",
    "########################################################################\n",
    "# See `here <https://pytorch.org/docs/stable/notes/serialization.html>`_\n",
    "# for more details on saving PyTorch models.\n",
    "#\n",
    "# 5. Test the network on the test data\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#\n",
    "# We have trained the network for 2 passes over the training dataset.\n",
    "# But we need to check if the network has learnt anything at all.\n",
    "#\n",
    "# We will check this by predicting the class label that the neural network\n",
    "# outputs, and checking it against the ground-truth. If the prediction is\n",
    "# correct, we add the sample to the list of correct predictions.\n",
    "#\n",
    "# Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# Next, let's load back in our saved model (note: saving and re-loading the model\n",
    "# wasn't necessary here, we only did it to illustrate how to do so):\n",
    "\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "########################################################################\n",
    "# Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n",
    "    outputs = net(images)\n",
    "\n",
    "########################################################################\n",
    "# The outputs are energies for the 10 classes.\n",
    "# The higher the energy for a class, the more the network\n",
    "# thinks that the image is of the particular class.\n",
    "# So, let's get the index of the highest energy:\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n",
    "\n",
    "########################################################################\n",
    "# The results seem pretty good.\n",
    "#\n",
    "# Let us look at how the network performs on the whole dataset.\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "########################################################################\n",
    "# That looks way better than chance, which is 10% accuracy (randomly picking\n",
    "# a class out of 10 classes).\n",
    "# Seems like the network learnt something.\n",
    "#\n",
    "# Hmmm, what are the classes that performed well, and the classes that did\n",
    "# not perform well:\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "########################################################################\n",
    "# Okay, so what next?\n",
    "#\n",
    "# How do we run these neural networks on the GPU?\n",
    "#\n",
    "# Training on GPU\n",
    "# ----------------\n",
    "# Just like how you transfer a Tensor onto the GPU, you transfer the neural\n",
    "# net onto the GPU.\n",
    "#\n",
    "# Let's first define our device as the first visible cuda device if we have\n",
    "# CUDA available:\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n",
    "    del dataiter\n",
    "# %%%%%%INVISIBLE_CODE_BLOCK%%%%%%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
